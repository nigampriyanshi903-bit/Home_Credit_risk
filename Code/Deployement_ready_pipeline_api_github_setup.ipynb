{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7684123b-505c-4a6e-811a-e8804865937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pipeline Test Starting ---\n",
      "ERROR: Model file missing at startup: [Errno 2] No such file or directory: 'models/xgb_model.pkl'. Check 'models/' directory.\n",
      "\n",
      "TEST FAILED: An error occurred during execution. Check model files. Error: [Errno 2] No such file or directory: 'models/xgb_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class CreditRiskPipeline:\n",
    "    \"\"\"\n",
    "    Production-ready pipeline class to load the model, scaler, and features, \n",
    "    and handle preprocessing and prediction in one consistent step.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # NOTE: Paths assume execution from the root project directory (credit-risk-scorecard)\n",
    "        try:\n",
    "            # This loads your pre-saved model, scaler, and feature list.\n",
    "            self.model = joblib.load(\"models/xgb_model.pkl\")\n",
    "            self.scaler = joblib.load(\"models/scaler.pkl\")\n",
    "            self.features_list = joblib.load(\"models/features_list.pkl\")\n",
    "            print(\"Pipeline initialized: Model, Scaler, and Features loaded successfully.\")\n",
    "        except FileNotFoundError as e:\n",
    "            # This error will show if model files are not found.\n",
    "            print(f\"ERROR: Model file missing at startup: {e}. Check 'models/' directory.\")\n",
    "            raise\n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame) -> np.ndarray:\n",
    "        # 1. Fills missing values with 0.\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        # 2. Reorders/aligns columns as required by the model.\n",
    "        missing_cols = set(self.features_list) - set(df.columns)\n",
    "        for c in missing_cols:\n",
    "            df[c] = 0.0 \n",
    "            \n",
    "        df = df[self.features_list]\n",
    "\n",
    "        # 3. Scales (standardizes) the data.\n",
    "        df_scaled = self.scaler.transform(df)\n",
    "        return df_scaled\n",
    "    \n",
    "    def predict(self, df: pd.DataFrame) -> tuple[float, int]:\n",
    "        X = self.preprocess(df)\n",
    "        # Predicts the probability of Class 1 (Default).\n",
    "        prob = self.model.predict_proba(X)[:, 1][0] \n",
    "        # Returns 1 (Risk) if the default probability is greater than 0.30.\n",
    "        pred = (prob > 0.30).astype(int)\n",
    "        return prob, pred\n",
    "\n",
    "# --- TESTING CODE (Now you will get output) ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data for testing (must match the features used by the model)\n",
    "    sample_data = {\n",
    "        'AMT_INCOME_TOTAL': [145000.0],\n",
    "        'AMT_CREDIT': [520000.0],\n",
    "        'AGE': [42],\n",
    "        'YEARS_EMPLOYED': [8.0],\n",
    "        'EXT_SOURCE_1': [0.61],\n",
    "        'EXT_SOURCE_2': [0.42],\n",
    "        'EXT_SOURCE_3': [0.68],\n",
    "        'DAYS_LATE_EMI_RATIO': [0.04],\n",
    "        'CREDIT_UTILIZATION': [0.29]\n",
    "    }\n",
    "    test_df = pd.DataFrame(sample_data)\n",
    "\n",
    "    print(\"\\n--- Pipeline Test Starting ---\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Create an object of the class (This will load the files)\n",
    "        risk_pipeline = CreditRiskPipeline()\n",
    "        \n",
    "        # 2. Call the predict method\n",
    "        probability, prediction = risk_pipeline.predict(test_df)\n",
    "        \n",
    "        # 3. Print the result\n",
    "        print(\"\\nPrediction Result:\")\n",
    "        print(f\"Default Probability (Class 1): {probability:.4f}\")\n",
    "        print(f\"Risk Flag (Prediction): {prediction} (1=High Risk)\")\n",
    "        \n",
    "        print(\"\\nTest Complete: Pipeline executed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nTEST FAILED: An error occurred during execution. Check model files. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8e8b64-9fdf-46aa-a020-b446d722ef15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CreditRiskPipeline\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# --- Pydantic Model for Request Body Validation ---\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define the expected structure of the incoming JSON data\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pipeline'"
     ]
    }
   ],
   "source": [
    "# Save this file as app.py\n",
    "\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from pipeline import CreditRiskPipeline\n",
    "import os\n",
    "\n",
    "# --- Pydantic Model for Request Body Validation ---\n",
    "# Define the expected structure of the incoming JSON data\n",
    "class LoanData(BaseModel):\n",
    "    # These fields must match the features used in your pipeline/sample request\n",
    "    AMT_INCOME_TOTAL: float\n",
    "    AMT_CREDIT: float\n",
    "    AGE: int\n",
    "    YEARS_EMPLOYED: float\n",
    "    EXT_SOURCE_1: float\n",
    "    EXT_SOURCE_2: float\n",
    "    EXT_SOURCE_3: float\n",
    "    DAYS_LATE_EMI_RATIO: float = 0.0  # Setting defaults for optional/derived features\n",
    "    CREDIT_UTILIZATION: float = 0.0 # Setting defaults for optional/derived features\n",
    "\n",
    "\n",
    "# --- FastAPI Application Setup ---\n",
    "app = FastAPI(\n",
    "    title=\"Credit Risk Scoring API\", \n",
    "    description=\"Real-time prediction service using XGBoost pipeline.\"\n",
    ")\n",
    "\n",
    "# Initialize the pipeline globally (only once at app startup)\n",
    "# This loads the model, scaler, and features list into memory\n",
    "try:\n",
    "    pipeline = CreditRiskPipeline() \n",
    "except Exception as e:\n",
    "    print(f\"FATAL: Failed to initialize pipeline. Check models directory. Error: {e}\")\n",
    "    # Raise the error to prevent the app from starting with a broken pipeline\n",
    "    raise\n",
    "\n",
    "\n",
    "# --- API Endpoint ---\n",
    "@app.post(\"/predict\")\n",
    "def predict_risk(data: LoanData):\n",
    "    \"\"\"\n",
    "    Accepts loan application data (JSON) and returns default probability and risk flag.\n",
    "    Risk Flag is 1 if probability > 0.30.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert incoming Pydantic model data to a DataFrame (required by the pipeline)\n",
    "        # data.model_dump() converts Pydantic model to a standard dict\n",
    "        df = pd.DataFrame([data.model_dump()])\n",
    "        \n",
    "        # Predict using the prepared pipeline\n",
    "        prob, pred = pipeline.predict(df)\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"default_probability\": float(prob),\n",
    "            \"risk_flag\": int(pred) # 1 = High Risk (Default predicted), 0 = Low Risk\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # Catch prediction-specific errors (e.g., unexpected data format)\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"Prediction failed due to processing error: {e}\"\n",
    "        }\n",
    "\n",
    "\n",
    "# --- Local Run Command ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Command to run locally: python app.py\n",
    "    # This uses uvicorn directly via the Python script\n",
    "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c89667e-4542-44a8-97c2-5491378d880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.122.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pydantic in c:\\programdata\\anaconda3\\lib\\site-packages (2.8.2)\n",
      "Collecting starlette<0.51.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from fastapi) (4.15.0)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi)\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Downloading fastapi-0.122.0-py3-none-any.whl (110 kB)\n",
      "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "Installing collected packages: annotated-doc, uvicorn, starlette, fastapi\n",
      "Successfully installed annotated-doc-0.0.4 fastapi-0.122.0 starlette-0.50.0 uvicorn-0.38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn pandas pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e429fc-1633-4a50-bde4-e77b1f156cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
